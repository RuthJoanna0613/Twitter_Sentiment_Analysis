{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kaushik/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "import tweepy as tw\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys required to connect to Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consumer_Key=\"7ULNGRHNK9zJIxjc5KLxuMTeZ\"\n",
    "Consumer_Secret=\"1jPRtvBFxvZwUzd9Gk9gUvYSMnLHrBEQrcVieQjGeEDqSPnnTf\"\n",
    "Access_Token=\"1458418334081425410-GiOCzDRZDkCVCOxPgVcpBSv7454OQV\"\n",
    "Access_Secret=\"k58HmCgCHH7cfjChhMJyhJSHeZ0UGo6f0MjYNxR0H1gt6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to authenticate with Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_api_authentication(Consumer_Key, Consumer_Secret, Access_Token, Access_Secret):\n",
    "    \"\"\"\n",
    "        /********------------------Function to authenticate with Twitter API------------------------------********/\n",
    "             \n",
    "                 - Consumer_Key: Provided by Twitter API dashboard\n",
    "                 - Consumer_Secret: Secret key provided by Twitter API dashboard\n",
    "                 - Access_Token: Token provided by Twitter API dashboard\n",
    "                 - Access_Secret: Secret Access key provided by Twitter API dashboard\n",
    "            \n",
    "            Please check the twitter API docs for more information: https://developer.twitter.com/en/docs/twitter-api/getting-started/getting-access-to-the-twitter-api\n",
    "        /********-----------------------------------------------------------------------------------------********/\n",
    "    \"\"\"\n",
    "    auth = tw.OAuthHandler(Consumer_Key,Consumer_Secret)\n",
    "    auth.set_access_token(Access_Token,Access_Secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit = True)\n",
    "    return api\n",
    "api = tweet_api_authentication(Consumer_Key, Consumer_Secret, Access_Token, Access_Secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fetch tweets for API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tweets_from_api(key_word_string, api_object):\n",
    "    \"\"\"\n",
    "        /*****------------------Function to fetch tweets from Twitter API-------------------------******/\n",
    "        \n",
    "            - key_word_string: Enter a string with keywords to fetch tweets\n",
    "                               example: Food OR food OR Foodie OR Delicious OR Breakfast OR Lunch OR Dinner\n",
    "            - api_object: Twitter API authenticated object. (Check func tweet_api_authentication() to create object)\n",
    "\n",
    "        /******----------------------------------------------------------------------------------******/\n",
    "    \"\"\"\n",
    "    search_tweets = key_word_string +  \"-filter:retweets\"\n",
    "    tweets = tw.Cursor(api_object.search_tweets,\n",
    "                            q = search_tweets,\n",
    "                            lang=\"en\",\n",
    "                            tweet_mode=\"extended\"\n",
    "                            ).items(5)\n",
    "    tweets_list = [[tweet.created_at, tweet.place, tweet.user.name, \n",
    "                         tweet.full_text] for tweet in tweets]\n",
    "    \n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to create a database and new tables for each tweet fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class database_operations in module __main__:\n",
      "\n",
      "class database_operations(builtins.object)\n",
      " |  database_operations(table_name, tweets_list)\n",
      " |  \n",
      " |  /*****________________Class to write and read tweets into database________________*****/\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, table_name, tweets_list)\n",
      " |      While initializing class object pass arguements:\n",
      " |          - table_name: Name of table to be created for tweets\n",
      " |          - tweets_list: List of tweets fetched from API (The list must contain, Date, Place, Username, Tweet)\n",
      " |                         Check func fetch_tweets_from_api() for more help\n",
      " |  \n",
      " |  clean_tweet(self, txt)\n",
      " |      Function to remove urls, symbols, retweet symbols\n",
      " |          - txt: Text to be cleaned\n",
      " |  \n",
      " |  create_connection(self)\n",
      " |      Create Connection with tweets database using SQLLite3\n",
      " |  \n",
      " |  create_table_from_dataframe(self)\n",
      " |      Creating SQLLite3 Table from a pandas dataframe with given list of tweets\n",
      " |      Database Columns = ['Created at', 'Place', 'User', 'Text']\n",
      " |  \n",
      " |  get_table(self)\n",
      " |      Returns the table name of current object\n",
      " |  \n",
      " |  read_from_table(self)\n",
      " |      Reading data from SQLLite3 DATABASE tweets_database\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "food\n",
      "read \n",
      "                   Created at Place                             User  \\\n",
      "0  2021-12-06 21:15:46+00:00  None                       Schwaüôè‚õàÔ∏è ”ô   \n",
      "1  2021-12-06 21:05:09+00:00  None  üïØüôèùó£ùóòùóßùóòùó•üôèüïØ#ReplaceMerrickGarland   \n",
      "2  2021-12-06 21:02:32+00:00  None                    Johnny Heller   \n",
      "3  2021-12-06 20:58:42+00:00  None                            üåΩSamüåΩ   \n",
      "4  2021-12-06 20:57:43+00:00  None                         Meta Mad   \n",
      "\n",
      "                                              Tweets  \\\n",
      "0  What sucks is that Trump can literally confess...   \n",
      "1  @Angry_Staffer Yeah, Garland still sucks. Let ...   \n",
      "2  GOP heroes like Trump, Flynn, Boebert, MTG, Ga...   \n",
      "3  @LeftFlankVets It sucks, but also I‚Äôm interest...   \n",
      "4  I find it disturbing that Border Patrol and DH...   \n",
      "\n",
      "                                      Cleaned_Tweets  \n",
      "0  What sucks is that Trump can literally confess...  \n",
      "1   Yeah, Garland still sucks. Let me know when h...  \n",
      "2  GOP heroes like Trump, Flynn, Boebert, MTG, Ga...  \n",
      "3   It sucks, but also I‚Äôm interested in seeing w...  \n",
      "4  I find it disturbing that Border Patrol and DH...  \n"
     ]
    }
   ],
   "source": [
    "class database_operations():\n",
    "    \"\"\"\n",
    "    \n",
    "        /*****________________Class to write and read tweets into database________________*****/   \n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, table_name, tweets_list):\n",
    "        \"\"\"\n",
    "        \n",
    "            While initializing class object pass arguements:\n",
    "                - table_name: Name of table to be created for tweets\n",
    "                - tweets_list: List of tweets fetched from API (The list must contain, Date, Place, Username, Tweet)\n",
    "                               Check func fetch_tweets_from_api() for more help\n",
    "        \"\"\"\n",
    "        self.table_name = table_name\n",
    "        self.tweets_list = tweets_list\n",
    "    \n",
    "    def get_table(self):\n",
    "        \"\"\"\n",
    "        \n",
    "            Returns the table name of current object\n",
    "        \"\"\"\n",
    "        return self.table_name\n",
    "    \n",
    "    def create_connection(self):\n",
    "        \"\"\"\n",
    "        \n",
    "            Create Connection with tweets database using SQLLite3\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect('tweets_database')\n",
    "        cursor = conn.cursor()\n",
    "        return [conn, cursor]\n",
    "    \n",
    "    def clean_tweet(self, txt):\n",
    "        \"\"\"\n",
    "            Function to remove urls, symbols, retweet symbols\n",
    "                - txt: Text to be cleaned\n",
    "        \"\"\"\n",
    "        txt = re.sub(r'@[A-Za-z0-9_]+', '', txt) # Keeps text A-Z, a-z, 0-9\n",
    "        txt = re.sub(r'#[A-Z0-9]+', '', txt)\n",
    "        txt = re.sub(r'RT : ', '', txt)\n",
    "        txt = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', txt) # remove url\n",
    "        txt = re.sub(r'&amp;', '', txt)\n",
    "        txt = re.sub(r'√∞≈∏‚Ñ¢', '', txt)\n",
    "        txt = re.sub(r'\\n', ' ', txt) \n",
    "        return txt\n",
    "        \n",
    "    def create_table_from_dataframe(self):\n",
    "        \"\"\"\n",
    "            Creating SQLLite3 Table from a pandas dataframe with given list of tweets\n",
    "            Database Columns = ['Created at', 'Place', 'User', 'Text']\n",
    "        \"\"\"\n",
    "        conn, cursor = self.create_connection()\n",
    "        cursor.execute(f\"CREATE TABLE IF NOT EXISTS {self.table_name} (created_at text, place text, user text, tweet text, cleaned_tweets text)\")\n",
    "        conn.commit()\n",
    "        tweets_df = pd.DataFrame(self.tweets_list, columns = ['Created at', 'Place', 'User', 'Tweets'])\n",
    "        tweets_df['Cleaned_Tweets'] = tweets_df['Tweets'].apply(self.clean_tweet)\n",
    "        tweets_df.to_sql(self.table_name, conn, if_exists='replace', index = False)\n",
    "        \n",
    "    def read_from_table(self):\n",
    "        \"\"\"\n",
    "            Reading data from SQLLite3 DATABASE tweets_database \n",
    "            \n",
    "        \"\"\"\n",
    "        conn, cursor = self.create_connection()\n",
    "        cursor.execute(f\"SELECT * FROM {self.table_name}\")\n",
    "        tweets_df = pd.DataFrame(cursor.fetchall(), columns = ['Created at', 'Place', 'User', \n",
    "                                                               'Tweets', 'Cleaned_Tweets'])\n",
    "        return tweets_df\n",
    "\n",
    "    # Food OR food OR Foodie OR Delicious OR Breakfast OR Lunch OR Dinner\n",
    "key_words = \"trump sucks\"\n",
    "tweets_list = fetch_tweets_from_api(key_words, api)\n",
    "help(database_operations)\n",
    "db = database_operations('food', tweets_list)\n",
    "db.create_table_from_dataframe()\n",
    "print(db.get_table())\n",
    "tweets_df = db.read_from_table()\n",
    "print(\"read \\n\", tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: What sucks is that Trump can literally confess to felonies on TV and not lose any supporters. \n",
      "this tweet is 35.5% negative, 54.9% neutral, 9.5% positive\n",
      "\n",
      "tweet:  Yeah, Garland still sucks. Let me know when he indicts Trump, till then, everything else is fixing the car‚Äôs flat tire while the engine is on fire.\n",
      "this tweet is 15.8% negative, 77.2% neutral, 7.1% positive\n",
      "\n",
      "tweet: GOP heroes like Trump, Flynn, Boebert, MTG, Gaetz, Cawthorne, Cruz, Paul, Gomert, Jordan are the kinds of people good people want nothing to do with.  The GOP fights science, sensible gun control, promote racial/ethnic hatred, hate mask  vax mandates... In short - the GOP sucks.\n",
      "this tweet is 25.0% negative, 54.8% neutral, 20.3% positive\n",
      "\n",
      "tweet:  It sucks, but also I‚Äôm interested in seeing where that trend goes in the next couple years. Like trump‚Äôs spike in his final year was absolutely massive. If Biden also keeps screwing this up, he‚Äôs basically handing trump a second term so that blows.\n",
      "this tweet is 8.2% negative, 78.2% neutral, 13.6% positive\n",
      "\n",
      "tweet: I find it disturbing that Border Patrol and DHS policy is, in essence, to eject refugees into Mexico. They treat people like garbage to be dumped. It's not much better than what the Trump regime was doing. Sorry, but Centrism sucks. Centrism is Republican Lite on this issue. ad\n",
      "this tweet is 18.5% negative, 75.0% neutral, 6.6% positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class handle_model():\n",
    "    def __init__(self, ml_model):\n",
    "        \"\"\"\n",
    "            While initializing class you need to pass the model as an arguement\n",
    "                - model: The model you want to use for Sentiment Analysis\n",
    "        \"\"\"\n",
    "        self.ml_model = ml_model\n",
    "    \n",
    "    def predict(self, tweets_df):\n",
    "        \"\"\"\n",
    "            Function to predict sentiments of given tweets\n",
    "                - tweets_df: tweets dataframe created from fetching tweets from API, more help look at\n",
    "                  class database_operations\n",
    "        \"\"\"\n",
    "        key_list = ['neg', 'neu', 'pos']\n",
    "        for index, tweet in tweets_df['Cleaned_Tweets'].iteritems():\n",
    "            score = self.ml_model.polarity_scores(tweet)\n",
    "            print(f\"tweet: {tweet}\")\n",
    "            print(f\"this tweet is {round(score['neg']*100, 2)}% negative, {round(score['neu']*100, 2)}% neutral, {round(score['pos']*100, 2)}% positive\")\n",
    "            print()\n",
    "\n",
    "m = handle_model(SentimentIntensityAnalyzer())            \n",
    "m.predict(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, redirect, url_for, session\n",
    "from werkzeug.utils import secure_filename\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger('HELLO WORLD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/upload',methods=['POST'])\n",
    "def uploadFile():\n",
    "    app.logger.info(\"The name is \" + request.form['Name'])\n",
    "    return 'Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "INFO:__main__:The name is Kaushik\n",
      "INFO:werkzeug:127.0.0.1 - - [06/Dec/2021 22:48:15] \"\u001b[37mPOST /upload HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(debug=True, host=\"127.0.0.1\", use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
